{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\r\n",
    "from nltk.tokenize import sent_tokenize\r\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\r\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\transformers\\generation\\utils.py:1357: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: What is the significance of inherited Tendencies? <sep> What is the\n",
      "Question 2: What is the purpose of the test? <sep> What is the purpose of the test? <sep> What\n",
      "Question 3: What is the main object of a school subject? <sep> What is the main object of\n",
      "Question 4: What is the sense organ that is a special adaptation of? <sep> What is the sense organ\n",
      "Question 5: What is the CONTENTS PAGE CHAPTER I? <sep>\n",
      "Question 6: What principle is 132 Mendelian? <sep> What principle is 132 Mendelian?\n",
      "Question 7: What are the key factors in life? <sep> What are the key factors in life? <sep> What\n",
      "Question 8: What is the truth about habits? <sep> What is the truth about habits? <sep> What is the\n",
      "Question 9: What is the sense organ in Figure II? <sep> What is the sense organ in Figure II?\n",
      "Question 10: What is the basis of the habit? <sep> What is the basis of the habit? <sep> What\n",
      "Question 11: What is the rule of a mental characteristic? <sep> What is the rule of a mental\n",
      "Question 12: What makes thought easier and its accomplishment greater? <sep> What is the name of Csar\n",
      "Question 13: What is the psychological attitude? <sep> What is the psychological attitude? <sep> What is the psychological attitude\n",
      "Question 14: What should children be trained in a way that will make them socially efficient? <sep> What\n",
      "Question 15: What is the purpose of a person to induce an emotional state? <sep> What is the purpose\n",
      "Question 16: What is the fundamentals of child study? <sep> What chapter is the fundamentals of child study\n",
      "Question 17: What is the inference that we must infer from our own in similar circumstances? <sep> What\n",
      "Question 18: What is the point we feel surest about? <sep> What is the point we feel surest\n",
      "Question 19: What is the explanation for the explanation? <sep> What is the explanation for the explanation? <sep> What\n",
      "Question 20: How many people change their ranks? <sep> How many people improve their ranks? <sep> How many people\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\r\n",
    "    document = fitz.open(pdf_path)\r\n",
    "    text = \"\"\r\n",
    "    for page_num in range(len(document)):\r\n",
    "        page = document.load_page(page_num)\r\n",
    "        text += page.get_text()\r\n",
    "    return text\r\n",
    "\r\n",
    "def process_text(text):\r\n",
    "    sentences = sent_tokenize(text)\r\n",
    "    return sentences\r\n",
    "\r\n",
    "def generate_questions(text):\r\n",
    "    model_name = \"valhalla/t5-small-e2e-qg\"\r\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name)\r\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_name)\r\n",
    "\r\n",
    "    input_text = \"generate questions: \" + text\r\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\r\n",
    "\r\n",
    "    outputs = model.generate(input_ids)\r\n",
    "    questions = tokenizer.decode(outputs[0], skip_special_tokens=True)\r\n",
    "    return questions\r\n",
    "\r\n",
    "def main(pdf_path):\r\n",
    "    text = extract_text_from_pdf(pdf_path)\r\n",
    "    sentences = process_text(text)\r\n",
    "    random.shuffle(sentences)\r\n",
    "    sentences = sentences[:20]\r\n",
    "    questions = [generate_questions(sentence) for sentence in sentences]\r\n",
    "    return questions\r\n",
    "\r\n",
    "pdf_path = \"./The-Science-of-Human-Nature.pdf\"\r\n",
    "questions = main(pdf_path)\r\n",
    "for i, question in enumerate(questions):\r\n",
    "    print(f\"Question {i+1}: {question}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16eb897c26cdfcf18817bc60a8e0737e3939ff1e8491198c807979170104e811"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}